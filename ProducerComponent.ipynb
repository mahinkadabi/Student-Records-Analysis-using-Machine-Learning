{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3IE7evqk9i6",
        "outputId": "8a44dcd2-f089-44b6-ed61-549c712d4c40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: confluent_kafka in /usr/local/lib/python3.7/dist-packages (1.9.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install confluent_kafka"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import json\n",
        "from uuid import uuid4\n",
        "from confluent_kafka import Producer"
      ],
      "metadata": {
        "id": "Y89CVMjglQWm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('unseenData.json.json')"
      ],
      "metadata": {
        "id": "xDbImAbQlZl0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = json.load(f)"
      ],
      "metadata": {
        "id": "FDtSMy9RlsE5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keys = []\n",
        "for i in data:\n",
        "    keys.append(i['id'])\n",
        "print(keys)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHr2xyjnl0hF",
        "outputId": "882e110b-2e99-44af-a696-c50b1385050a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3, 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dicts = {}\n",
        "for i in keys:\n",
        "    dicts[i] = data[i]"
      ],
      "metadata": {
        "id": "X6_rpbTomM7e"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_enc={}\n",
        "for i in keys:\n",
        "  json_enc[i]=str(dicts[i]).encode()"
      ],
      "metadata": {
        "id": "CMveAmMimOj7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_enc[3]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzvsmlKEoSjm",
        "outputId": "cfc54001-a02d-40e4-82bb-5eaa7d32cb59"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b\"{'FIELD1': 3, 'id': 3, 'major': 'Electric Engineering', 'gender': 'F', 'c01': '84.84848484848484', 'c02': '86.70520231213872', 'c03': '84.30232558139535', 'c04': 64.5, 'c05': '63.537906137184116', 'c06': '83.41013824884793', 'c07': '80.92105263157895', 'c08': '84.41558441558442', 'c09': '85.51401869158879', 'c10': '88.98305084745763', 'academic': '80.71377637142608', 'campus': 2, 'internship': 10, 'AtRisk_academic': 0, 'AtRisk_campus': 1, 'AtRisk_internship': 0, 'At_Risk': 1, 'graduate_program': '0.3688911565731687', 'goverment': '0.15803058089288388', 'industry': '0.38374328591141266', 'placement': '0.9106650233774651', 'annual': '122608.70283935191'}\""
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def delivery_report(errmsg, msg):\n",
        "    \"\"\"\n",
        "    Reports the Failure or Success of a message delivery.\n",
        "    Args:\n",
        "        errmsg  (KafkaError): The Error that occurred while message producing.\n",
        "        data    (Actual message): The message that was produced.\n",
        "    Note:\n",
        "        In the delivery report callback the Message.key() and Message.value()\n",
        "        will be the binary format as encoded by any configured Serializers and\n",
        "        not the same object that was passed to produce().\n",
        "        If you wish to pass the original object(s) for key and value to delivery\n",
        "        report callback we recommend a bound callback or lambda where you pass\n",
        "        the objects along.\n",
        "    \"\"\"   \n",
        "    if errmsg is not None:\n",
        "        print(\"Delivery failed for Message: {} : {}\".format(msg.key(), errmsg))\n",
        "        return\n",
        "    print('Message: {} successfully produced to Topic: {} Partition: [{}] at offset {}'.format(\n",
        "        msg.key(), msg.topic(), msg.partition(), msg.offset()))"
      ],
      "metadata": {
        "id": "ed4Mr2eooYRj"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kafka_topic_name = \"Producer_Exam2\"   \n",
        "#Change your Kafka Topic Name here. For this Example: lets assume our Kafka Topic has 3 Partitions==>  0,1,2\n",
        "#And We are producing messages uniformly to all partitions.\n",
        "#We are sending the message as ByteArray.\n",
        "#If We want read the same message from a Java Consumer Program\n",
        "#We can configure KEY_DESERIALIZER_CLASS_CONFIG = ByteArrayDeserializer.class\n",
        "# and VALUE_DESERIALIZER_CLASS_CONFIG = ByteArrayDeserializer.class\n",
        " \n",
        "## mysecret = \"yourjksPassword\"\n",
        "#you can call remote API to get JKS password instead of hardcoding like above\n",
        " \n",
        "print(\"Starting Kafka Producer\")   \n",
        "conf = {\n",
        "        'bootstrap.servers' : 'pkc-6ojv2.us-west4.gcp.confluent.cloud:9092',\n",
        "        'security.protocol' : 'SASL_SSL',\n",
        "        'sasl.mechanisms':'PLAIN',\n",
        "        'sasl.username':'U3QU2LZ6N4I3AUIV',\n",
        "        'sasl.password' : 'OB5BU8gzLVsSvwogAk2+9F733rFNTqqmQPaCGU1hBdJQLvBsVETF/keSuo5R981M'\n",
        "        \n",
        "        }\n",
        "         \n",
        "print(\"connecting to Kafka topic...\")\n",
        "producer1 = Producer(conf)\n",
        " \n",
        "# Trigger any available d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjZt8JBkod6a",
        "outputId": "5a83c195-eeef-4839-d08e-538f1ebfd8e6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Kafka Producer\n",
            "connecting to Kafka topic...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Asynchronously produce a message, the delivery report callback\n",
        "    # will be triggered from poll() above, or flush() below, when the message has\n",
        "    # been successfully delivered or failed permanently.\n",
        "    for i in keys:\n",
        "      producer1.produce(topic=kafka_topic_name, key=str(i), value=json_enc[i], on_delivery=delivery_report)\n",
        "    \n",
        "    # Wait for any outstanding messages to be delivered and delivery report\n",
        "    # callbacks to be triggered.\n",
        "    producer1.flush()\n",
        "     \n",
        "except Exception as ex:\n",
        "    print(\"Exception happened :\",ex)\n",
        "     \n",
        "    print(\"\\n Stopping Kafka Producer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gxut8R8VogDv",
        "outputId": "9fa0befb-fc1f-4eaf-c8b7-fd7f9afa828f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Message: b'1' successfully produced to Topic: Producer_Exam2 Partition: [3] at offset 4\n",
            "Message: b'4' successfully produced to Topic: Producer_Exam2 Partition: [3] at offset 5\n",
            "Message: b'2' successfully produced to Topic: Producer_Exam2 Partition: [2] at offset 2\n",
            "Message: b'3' successfully produced to Topic: Producer_Exam2 Partition: [1] at offset 2\n",
            "Message: b'0' successfully produced to Topic: Producer_Exam2 Partition: [4] at offset 2\n"
          ]
        }
      ]
    }
  ]
}